{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c04173ee",
   "metadata": {},
   "source": [
    "# Labb 2 (vecka 2): Klassificering – välja rätt metric och justera threshold\n",
    "\n",
    "\n",
    "## Mål\n",
    "Ni ska träna en klassificeringsmodell och:\n",
    "1) välja **vilken utvärderings-metric som är mest rimlig** i ett givet scenario (accuracy / precision / recall / F1)  \n",
    "2) **anpassa modellen** utifrån ert scenario genom att (a) välja en modellfamilj och (b) **justera threshold** för att få en bättre trade-off.\n",
    "\n",
    "> Fokus i den här labben är inte att skriva mycket kod från scratch,\n",
    "> utan att förstå **vad koden gör**, **varför vi gör stegen** och **hur vi tolkar resultaten**.\n",
    "\n",
    "---\n",
    "\n",
    "## Viktigt innan ni börjar\n",
    "- **Kodning i den här labben:**  \n",
    "  - `target = 1` = **positivt fall** (det ni vill hitta / larma om i scenariot)  \n",
    "  - `target = 0` = **negativt fall** (allt annat)\n",
    "\n",
    "\n",
    "- Fundera på: **Vilket fel är värst?**  \n",
    "  - *False Positive (FP)* = falsklarm  \n",
    "  - *False Negative (FN)* = miss\n",
    "- Ni kommer att se att det inte finns ett “perfekt” svar – ni måste välja en trade-off.\n",
    "\n",
    "---\n",
    "\n",
    "## Scenarion\n",
    "Läs igenom alla scenarion tillsammans. Välj sedan **ett** scenario per grupp.\n",
    "\n",
    "Ni får samma dataset och nästan samma kod – men “vad som är ett bra resultat” beror på situationen.\n",
    "\n",
    "### Scenario A: Kvalitetskontroll i produktion\n",
    "\n",
    "**Kodning:** `0 = OK`, `1 = Defekt`\n",
    "\n",
    "Ni har en modell som ska avgöra om en produkt är **OK** eller **Defekt**.  \n",
    "Om en defekt produkt slinker igenom blir det reklamation och missnöjda kunder.  \n",
    "Om en OK produkt felaktigt flaggas som defekt blir det onödigt svinn/omarbete.\n",
    "\n",
    "En defekt som slinker igenom kostar ungefär lika mycket som att kassera/omarbeta en OK produkt (i snitt).\n",
    "\n",
    "**Diskutera:**\n",
    "- Vad kostar FP respektive FN här – och varför?\n",
    "- Är det viktigast att *inte missa defekter* eller att *inte slösa på falsklarm*?\n",
    "- Vad skulle ni vilja veta mer om (kostnader, volymer, kapacitet) innan ni bestämmer er?\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario B: Supportteam – prioritera ärenden\n",
    "\n",
    "**Kodning:** `0 = Låg prio`, `1 = Hög prio`\n",
    "\n",
    "Ni ska förutsäga om ett inkommande ärende är **Hög prio** eller **Låg prio**.  \n",
    "När modellen flaggar “hög prio” går ärendet direkt till ett specialistteam.  \n",
    "Specialistteamet är dyrt och har begränsad kapacitet – men om ett *riktigt* högprio-ärende hamnar fel kan det bli dyrt på andra sätt (SLA, förlorade kunder).\n",
    "\n",
    "Specialistteamet hinner max ta 20 ärenden/dag. Om modellen flaggar fler blir kö och allt tappar värde.\n",
    "\n",
    "**Diskutera:**\n",
    "- Vad händer om ni flaggar för många som “hög prio”?\n",
    "- Vad händer om ni missar ett högprio-ärende?\n",
    "- Hur skulle ni beskriva en “rimlig” trade-off för teamet?\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario C: Säkerhet – upptäck intrång\n",
    "\n",
    "**Kodning:** `0 = Inte intrång`, `1 = Intrång`\n",
    "\n",
    "Ni övervakar systemloggar och ska förutsäga om en händelse är **Intrång** eller **Inte intrång**.  \n",
    "Ett falsklarm innebär att någon får kolla upp det i efterhand.  \n",
    "Ett missat intrång kan däremot få stora konsekvenser.\n",
    "\n",
    "Ett missat intrång kan innebära dataläcka och driftstopp; ett falsklarm tar 5–10 min att kontrollera.\n",
    "\n",
    "**Diskutera:**\n",
    "- Varför är det här ett typiskt “obalanserat” problem i verkligheten?\n",
    "- Vilket fel är värst: FP eller FN? (motivera)\n",
    "- Hur skulle ni kommunicera er trade-off till en icke-teknisk chef?\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario D: Marknad – hitta rätt målgrupp\n",
    "\n",
    "**Kodning:** `0 = Kommer inte köpa`, `1 = Kommer köpa (om de får kampanjen)`\n",
    "\n",
    "Ni ska välja vilka kunder som ska få en **kampanj** (positiv = “kommer troligen köpa om de får kampanjen”).  \n",
    "Varje skickad kampanj kostar pengar och riskerar att irritera kunder som inte är intresserade.  \n",
    "Samtidigt vill ni inte missa de kunder som faktiskt hade köpt.\n",
    "\n",
    "Ni vill både undvika spam och samtidigt inte missa intäkter — ledningen vill ha en ‘rimlig balans’.\n",
    "\n",
    "**Diskutera:**\n",
    "- Vad kostar FP respektive FN i det här fallet?\n",
    "- När kan det vara bättre att vara “snål” med kampanjer? När kan det vara bättre att vara “generös”?\n",
    "- Om ni bara fick skicka kampanjen till 10% av kunderna – hur påverkar det er strategi?\n",
    "\n",
    "---\n",
    "\n",
    "## Uppgifter\n",
    "1. Diskutera alla scenarion kort i gruppen, och välj sedan **ett** scenario att gå vidare med.\n",
    "2. Bestäm och skriv ner vilket misstag som känns värst i praktiken:  **FP** (false positives) eller **FN** (false negatives)? Varför?\n",
    "3. Välj en **primär metric** utifrån ert scenario och skriv en kort motivering:\n",
    "   - Accuracy / Precision / Recall / F1\n",
    "4. Kör notebooken fram till delen där ni **jämför flera modeller**.\n",
    "   - Stanna vid varje output och **tolka tillsammans**.\n",
    "5. Välj **en modell** att gå vidare med (t.ex. Logistic Regression / Decision Tree / Random Forest) och motivera kort:\n",
    "   - Varför den modellen känns rimlig för just ert scenario (tolkning, stabilitet, risk för överfitting, osv).\n",
    "6. Titta på modellens resultat på valideringsdatan:\n",
    "   - Confusion matrix  \n",
    "   - Accuracy / Precision / Recall / F1  \n",
    "   - PR-kurva  \n",
    "   Diskutera: *Ser det ut som ni får den typ av misstag ni helst vill undvika?*\n",
    "7. **Justera threshold** (ändra bara `THRESHOLD`) och kör om.\n",
    "   - Testa minst **tre** olika thresholds (t.ex. 0.2, 0.5, 0.8).\n",
    "   - Efter varje test: skriv ner vad som händer med **FP** och **FN**.\n",
    "8. Välj en threshold som ni kan **försvara** utifrån scenariot.\n",
    "   - Skriv 2–3 meningar: *Vad offrar ni? Vad vinner ni?*\n",
    "9. Kör sista delen (test-set) och jämför:\n",
    "   - er valda modell + threshold\n",
    "   - baseline (DummyClassifier)  \n",
    "   Diskutera: *Blev resultatet liknande på test? Om inte – varför kan det skilja?*\n",
    "\n",
    "### (Valfritt, om ni hinner)\n",
    "- Byt primär metric och se om ni hade valt en annan threshold eller annan modell.\n",
    "- Testa en annan modell och se om PR-kurvan förändras på ett sätt som påverkar ert beslut.\n",
    "\n",
    "---\n",
    "\n",
    "## Leverans (till helklassdiskussionen)\n",
    "När ni är klara ska ni kunna svara kort på:\n",
    "1) Vilket scenario valde ni och varför?\n",
    "2) Vilket fel (FP eller FN) är värst – och varför?\n",
    "3) Vilken metric valde ni som primär, och vilken modell valde ni?\n",
    "4) Vilken threshold valde ni och vilken trade-off accepterade ni?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84932603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m pip install numpy pandas matplotlib seaborn scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a2611d",
   "metadata": {},
   "source": [
    "## Skapa ett dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi skapar ett syntetiskt dataset så att vi kan styra svårighetsgrad och klassobalans.\n",
    "# Positiv klass = 1 (det ni \"larmar\" om).\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=5000,\n",
    "    n_features=20,\n",
    "    n_informative=6,\n",
    "    n_redundant=4,\n",
    "    n_repeated=0,\n",
    "    n_clusters_per_class=2,\n",
    "    weights=[0.92, 0.08],       # <-- klassobalans (8% positiva)\n",
    "    flip_y=0.02,                # <-- lite label noise\n",
    "    class_sep=1.0,              # <-- justera om ni vill göra det lättare/svårare\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "X = pd.DataFrame(X, columns=[f\"x{i:02d}\" for i in range(X.shape[1])])\n",
    "y = pd.Series(y, name=\"target\")\n",
    "\n",
    "y.value_counts(normalize=True).rename(\"andel\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0782a8c",
   "metadata": {},
   "source": [
    "## EDA (snabbt)\n",
    "\n",
    "Vi gör bara en **snabb koll på klassbalansen**.\n",
    "\n",
    "Poängen är att se om problemet är “obalanserat” (t.ex. få positiva fall).  \n",
    "Det påverkar ofta hur man ska tolka **accuracy** och varför **precision/recall** kan bli viktiga.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8104a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snabb titt på klassbalans\n",
    "\n",
    "counts = pd.Series(y).value_counts().sort_index()\n",
    "display(pd.DataFrame({\n",
    "    \"target\": counts.index,\n",
    "    \"antal\": counts.values,\n",
    "    \"andel\": (counts.values / counts.values.sum())\n",
    "}))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax.bar(counts.index.astype(str), counts.values)\n",
    "ax.set_xlabel(\"target (0/1)\")\n",
    "ax.set_ylabel(\"Antal\")\n",
    "ax.set_title(\"Klassbalans i datasetet\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cc402",
   "metadata": {},
   "source": [
    "## Train / Validation / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964e4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi vill ha en separat validation-del för att välja modell + threshold\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.25, stratify=y_trainval, random_state=RANDOM_SEED\n",
    ")  # => 60% train, 20% val, 20% test\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Val:\", X_val.shape, \" Test:\", X_test.shape)\n",
    "print(\"Andel positiva (train/val/test):\",\n",
    "      y_train.mean().round(3), y_val.mean().round(3), y_test.mean().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd3017",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98585be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline: gissa alltid majoritetsklassen\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\", random_state=RANDOM_SEED)\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_base = baseline.predict(X_val)\n",
    "\n",
    "def metrics_report(y_true, y_pred, title=\"\"):\n",
    "    return pd.Series({\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }, name=title)\n",
    "\n",
    "display(metrics_report(y_val, y_pred_base, \"Baseline (val)\"))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred_base)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot(values_format=\"d\")\n",
    "plt.title(\"Confusion matrix – Baseline (val)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cce3913",
   "metadata": {},
   "source": [
    "## Jämför modeller (CV på train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vi jämför tre vanliga modellfamiljer:\n",
    "# - Logistic Regression (linjär modell, ofta bra baseline)\n",
    "# - Decision Tree (icke-linjär, kan överanpassa)\n",
    "# - Random Forest (ensemble, ofta robust)\n",
    "\n",
    "models = {\n",
    "    \"logreg\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=2000, random_state=RANDOM_SEED, class_weight=\"balanced\"))\n",
    "    ]),\n",
    "    \"tree\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"clf\", DecisionTreeClassifier(random_state=RANDOM_SEED, max_depth=5, min_samples_leaf=20))\n",
    "    ]),\n",
    "    \"rf\": Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            n_estimators=200,\n",
    "            random_state=RANDOM_SEED,\n",
    "            n_jobs=-1,\n",
    "            max_depth=8,\n",
    "            min_samples_leaf=10\n",
    "        ))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"precision\": \"precision\",\n",
    "    \"recall\": \"recall\",\n",
    "    \"f1\": \"f1\",\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "rows = []\n",
    "for name, pipe in models.items():\n",
    "    out = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    row = {m: out[f\"test_{m}\"].mean() for m in scoring.keys()}\n",
    "    row[\"model\"] = name\n",
    "    rows.append(row)\n",
    "\n",
    "cv_results = pd.DataFrame(rows).set_index(\"model\")\n",
    "cv_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d7a7b5",
   "metadata": {},
   "source": [
    "## Er uppgift: välj primär metric och modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d9959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Välj EN primär metric baserat på ert scenario.\n",
    "# Skriv exakt en av: \"accuracy\"  \"precision\"  \"recall\"  \"f1\"\n",
    "PRIMARY_METRIC = \"f1\"  # <-- ÄNDRA här\n",
    "\n",
    "allowed_metrics = {\"accuracy\", \"precision\", \"recall\", \"f1\"}\n",
    "if PRIMARY_METRIC not in allowed_metrics:\n",
    "    raise ValueError(f\"PRIMARY_METRIC måste vara en av {allowed_metrics}. Du skrev: {PRIMARY_METRIC}\")\n",
    "\n",
    "PRIMARY_METRIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99fee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Välj en modell att gå vidare med.\n",
    "# Skriv exakt en av: \"logreg\"  \"tree\"  \"rf\"\n",
    "MODEL_NAME = \"logreg\"  # <-- ÄNDRA här\n",
    "\n",
    "allowed_models = set(models.keys())\n",
    "if MODEL_NAME not in allowed_models:\n",
    "    raise ValueError(f\"MODEL_NAME måste vara en av {allowed_models}. Du skrev: {MODEL_NAME}\")\n",
    "\n",
    "MODEL_NAME\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc53f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Träna den valda modellen på train och utvärdera på validation (med default threshold=0.5)\n",
    "\n",
    "model = models[MODEL_NAME]\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = model.predict(X_val)\n",
    "\n",
    "display(metrics_report(y_val, y_pred_val, f\"{MODEL_NAME} (val, threshold=0.5)\"))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred_val)\n",
    "ConfusionMatrixDisplay(cm).plot(values_format=\"d\")\n",
    "plt.title(f\"Confusion matrix – {MODEL_NAME} (val, threshold=0.5)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a443bd",
   "metadata": {},
   "source": [
    "## PR-kurva och threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f56d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# För att kunna flytta threshold behöver vi sannolikheter (predict_proba).\n",
    "# Alla våra modeller här stödjer predict_proba.\n",
    "\n",
    "proba_val = model.predict_proba(X_val)[:, 1]  # sannolikhet för klass 1\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_val, proba_val)\n",
    "\n",
    "ap = average_precision_score(y_val, proba_val)\n",
    "print(f\"Average precision (AP) på val: {ap:.3f}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(recall, precision)\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_title(\"Precision–Recall-kurva (val)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b335ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hjälpplot: hur precision/recall/F1 ändras när vi flyttar threshold\n",
    "# (thresholds har längd n-1 jämfört med precision/recall)\n",
    "\n",
    "thr = thresholds\n",
    "prec_thr = precision[:-1]\n",
    "rec_thr = recall[:-1]\n",
    "f1_thr = 2 * (prec_thr * rec_thr) / (prec_thr + rec_thr + 1e-12)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "ax.plot(thr, prec_thr, label=\"precision\")\n",
    "ax.plot(thr, rec_thr, label=\"recall\")\n",
    "ax.plot(thr, f1_thr, label=\"f1\")\n",
    "ax.set_xlabel(\"Threshold\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.set_title(\"Scores vs threshold (val)\")\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"threshold\": thr,\n",
    "    \"precision\": prec_thr,\n",
    "    \"recall\": rec_thr,\n",
    "    \"f1\": f1_thr\n",
    "}).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bdc87",
   "metadata": {},
   "source": [
    "### Er uppgift: välj ett threshold som passar ert scenario\n",
    "\n",
    "Nu kommer den viktiga delen: **ni kan göra modellen mer “strikt” eller mer “generös”**.\n",
    "\n",
    "- Högre threshold → modellen säger “1” mer sällan (färre larm)  \n",
    "- Lägre threshold → modellen säger “1” oftare (fler larm)\n",
    "\n",
    "**Diskutera medan ni testar:**\n",
    "- Vad händer med FP och FN när ni flyttar threshold?\n",
    "- Vilken förändring känns “rimlig” i ert scenario – och varför?\n",
    "- Vilken trade-off accepterar ni?\n",
    "\n",
    "> Ni ska inte “gissa” ett tal. Testa några olika värden och jämför.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387d905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ändra threshold och se vad som händer.\n",
    "THRESHOLD = 0.50  # <-- ÄNDRA här (t.ex. 0.2, 0.35, 0.65, 0.8)\n",
    "\n",
    "print(\"Proba min/max:\", proba_val.min(), proba_val.max())\n",
    "print(\"Unika proba (avrundat till 2 dec):\", len(np.unique(np.round(proba_val, 2))))\n",
    "\n",
    "y_pred_thr = (proba_val >= THRESHOLD).astype(int)\n",
    "\n",
    "display(metrics_report(y_val, y_pred_thr, f\"{MODEL_NAME} (val, threshold={THRESHOLD:.2f})\"))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred_thr)\n",
    "ConfusionMatrixDisplay(cm).plot(values_format=\"d\")\n",
    "plt.title(f\"Confusion matrix – {MODEL_NAME} (val, threshold={THRESHOLD:.2f})\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Extra visual: hur sannolikheterna ser ut (val)\n",
    "# Tolkning: om fördelningarna överlappar mycket blir trade-offen svårare.\n",
    "fig, ax = plt.subplots(figsize=(6,3))\n",
    "ax.hist(proba_val[y_val==0], bins=30, alpha=0.6, label=\"target=0\")\n",
    "ax.hist(proba_val[y_val==1], bins=30, alpha=0.6, label=\"target=1\")\n",
    "ax.axvline(THRESHOLD, linestyle=\"--\")\n",
    "ax.set_xlabel(\"Predikterad sannolikhet för klass 1\")\n",
    "ax.set_ylabel(\"Antal\")\n",
    "ax.set_title(\"Fördelning av predikterade sannolikheter (val)\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e44d1b",
   "metadata": {},
   "source": [
    "## Sluttest på test-setet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ae8beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# När ni är nöjda: träna om modellen på train+val (så vi utnyttjar mer data),\n",
    "# och utvärdera en enda gång på test-setet med ert valda threshold.\n",
    "\n",
    "final_model = models[MODEL_NAME]\n",
    "final_model.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "\n",
    "proba_test = final_model.predict_proba(X_test)[:, 1]\n",
    "y_pred_test = (proba_test >= THRESHOLD).astype(int)\n",
    "\n",
    "display(metrics_report(y_test, y_pred_test, f\"{MODEL_NAME} (test, threshold={THRESHOLD:.2f})\"))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "ConfusionMatrixDisplay(cm).plot(values_format=\"d\")\n",
    "plt.title(f\"Confusion matrix – {MODEL_NAME} (test, threshold={THRESHOLD:.2f})\")\n",
    "plt.show()\n",
    "\n",
    "# PR-kurva på test (för att se om samma trade-off håller)\n",
    "precision_t, recall_t, _ = precision_recall_curve(y_test, proba_test)\n",
    "ap_t = average_precision_score(y_test, proba_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(recall_t, precision_t)\n",
    "ax.set_xlabel(\"Recall\")\n",
    "ax.set_ylabel(\"Precision\")\n",
    "ax.set_title(f\"Precision–Recall-kurva (test), AP={ap_t:.3f}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a42cbf",
   "metadata": {},
   "source": [
    "## Förbättring mot baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline på test för jämförelse\n",
    "baseline.fit(pd.concat([X_train, X_val]), pd.concat([y_train, y_val]))\n",
    "y_pred_base_test = baseline.predict(X_test)\n",
    "\n",
    "report = pd.DataFrame([\n",
    "    metrics_report(y_test, y_pred_base_test, \"Baseline (test)\"),\n",
    "    metrics_report(y_test, y_pred_test, f\"{MODEL_NAME} (test, thr={THRESHOLD:.2f})\"),\n",
    "]).T\n",
    "\n",
    "report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
