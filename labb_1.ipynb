{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6981c4",
   "metadata": {},
   "source": [
    "# Labb 1 (vecka 1): Välja rätt metric och tunea Ridge\n",
    "\n",
    "Ni kommer att få 3 olika scenarion att utforska\n",
    "\n",
    "## Mål\n",
    "Ni ska träna en Ridge-regressionsmodell och:\n",
    "1) välja **vilken utvärderings-metric som är mest rimlig** i ett givet scenario. \n",
    "2) **optimera (tunea) modellen** mot den metricen genom att skapa ett bra grid för hyperparametern **alpha**.\n",
    "\n",
    "> Fokus i den här labben är inte att skriva mycket kod från scratch,\n",
    "> utan att förstå **vad koden gör**, **varför vi gör stegen** och **hur vi tolkar resultaten**.\n",
    "\n",
    "---\n",
    "\n",
    "## Scenarion\n",
    "Ni ska börja med att läsa igenom alla tre scenarion tillsammans och diskutera kort det som står under \"Diskutera\"\n",
    "\n",
    "Ni får samma dataset och samma modelltyp – men “vad som är ett bra fel” beror på situationen.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario A: Sjukhus – planera bemanning\n",
    "Ni förutspår **antal patienter** som kommer in nästa timme/dygn.\n",
    "\n",
    "- Om modellen ibland **underskattar rejält** → personal räcker inte, köerna växer, stress och risk ökar.\n",
    "- Om modellen **överskattar lite** → ofta “bara” ineffektivitet (men mindre akut än brist).\n",
    "- Små fel kan ni leva med – men **enstaka stora fel** kan bli riktigt dyra.\n",
    "\n",
    "**Diskutera:**\n",
    "Vilken metric passar bäst om vi vill **straffa stora missar extra mycket**?\n",
    "Motivera utifrån vad som är “dyrt” i scenariot.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario B: Butik – beställa varor\n",
    "Ni förutspår efterfrågan på en vara.\n",
    "\n",
    "- Ibland finns outliers (kampanjer, helger, väder, TikTok-trend) som gör att vissa dagar blir extremt annorlunda.\n",
    "- Ni vill att modellen ska vara bra på vanliga dagar, inte att den “optimerar” för att passa de få extremdagarna perfekt.\n",
    "- Tänk så här: vissa metrics överreagerar på stora fel. Om ett enstaka fel blir jättestort kan det dominera hela måttet och styra modellen för mycket.\n",
    "- I en butik kan det ofta vara bättre att modellen är stabil: hellre “okej” nästan varje dag än att den blir sämre på det normala bara för att jaga extrema toppar.\n",
    "\n",
    "**Diskutera:**\n",
    "Vilken metric passar bäst om vi vill vara mindre känsliga för enstaka extrema dagar?\n",
    "Motivera varför utifrån hur ni tror metricen “straffar” fel.\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario C: Rapportering – förklara modellens nytta för en icke-teknisk chef\n",
    "Ni ska presentera modellen för en chef som inte bryr sig om ML-detaljer.\n",
    "\n",
    "- Chefen frågar: “Hur mycket bättre är det här än att bara gissa ett standardvärde?”\n",
    "- En siffra som kan tolkas som **”hur mycket av variationen vi förklarar”** kan vara pedagogisk.\n",
    "- Ni vill ha något som funkar bra i en presentation, även om man ibland behöver förklara begränsningar.\n",
    "\n",
    "**Diskutera:**\n",
    "Vilken metric passar bäst som en **förklarings-/jämförelse-siffra**?\n",
    "Vad är bra med den – och vad kan vara missvisande?\n",
    "\n",
    "---\n",
    "\n",
    "## Uppgifter\n",
    "1. Diskutera alla tre scenarion kort i gruppen, och välj sedan ett scenario att gå vidare med.\n",
    "2. Kör notebooken fram till GridSearch-delen block för block och diskutera/tolka output tillsammans.\n",
    "3. Välj **primär metric** (MAE / RMSE / R²) utifrån ert scenario och skriv en kort motivering.\n",
    "4. Bygg ert **alpha-grid** (lista med testvärden).\n",
    "   - Poängen är att experimentera och se hur resultatet ändras.\n",
    "   - Testa gärna både små och stora alpha.\n",
    "5. Kör **GridSearchCV** och jämför:\n",
    "   - bästa alpha\n",
    "   - CV-resultat (kom ihåg att vissa scoring i scikit-learn blir “negativa”)\n",
    "   - testresultat (MAE, RMSE, R²)\n",
    "6. Diskutera i grupp:\n",
    "   - Varför valde ni just den metricen?\n",
    "   - Blev bästa alpha annorlunda om ni bytte metric? Varför kan det bli så?\n",
    "\n",
    "---\n",
    "\n",
    "Skulle ni hinna klart och har tid över. Testa då ett annat scenario\n",
    "\n",
    "> ## Leverans (presentera för klassen)\n",
    "> - Vi optimerade mot: (MAE/RMSE/R²)\n",
    "> - Varför: 2–3 meningar kopplat till scenario\n",
    "> - Bästa alpha: …\n",
    "> - Vad blev er metric på test-data?\n",
    "> - Om ni skulle gå vidare i verkligheten: 1 sak ni skulle testa (t.ex. fler features, annan modell, mer data, annan metric, större grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m pip install numpy pandas matplotlib seaborn scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set_theme()\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, r2_score\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3c0589",
   "metadata": {},
   "source": [
    "## Skapa ett dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9c8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_demand_dataset(n_days=800, outlier_fraction=0.03, random_seed=42):\n",
    "    rng_local = np.random.default_rng(random_seed)\n",
    "\n",
    "    weekday = rng_local.integers(0, 7, size=n_days)\n",
    "    marketing_spend = rng_local.gamma(shape=2.0, scale=50.0, size=n_days)\n",
    "    is_campaign = rng_local.binomial(1, 0.25, size=n_days)\n",
    "    competitor_discount = rng_local.binomial(1, 0.15, size=n_days)\n",
    "    temperature = rng_local.normal(loc=12, scale=8, size=n_days)\n",
    "\n",
    "    base = 120\n",
    "    weekday_effect = np.where(weekday < 5, 10, -15)\n",
    "    campaign_effect = is_campaign * 45\n",
    "    competitor_effect = competitor_discount * (-25)\n",
    "    marketing_effect = 0.35 * marketing_spend\n",
    "    temp_effect = 1.5 * temperature\n",
    "\n",
    "    noise = rng_local.normal(0, 20, size=n_days)\n",
    "    demand = base + weekday_effect + campaign_effect + competitor_effect + marketing_effect + temp_effect + noise\n",
    "\n",
    "    # outliers\n",
    "    n_outliers = int(n_days * outlier_fraction)\n",
    "    outlier_indices = rng_local.choice(n_days, size=n_outliers, replace=False)\n",
    "    shock = rng_local.normal(loc=220, scale=60, size=n_outliers)\n",
    "    demand[outlier_indices] += shock\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"marketing_spend\": marketing_spend,\n",
    "        \"weekday\": weekday,\n",
    "        \"is_campaign\": is_campaign,\n",
    "        \"competitor_discount\": competitor_discount,\n",
    "        \"temperature\": temperature,\n",
    "        \"demand\": demand\n",
    "    })\n",
    "\n",
    "    # lite missing values\n",
    "    missing_mask = rng_local.random(df.shape[0]) < 0.02\n",
    "    df.loc[missing_mask, \"temperature\"] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "df = generate_demand_dataset()\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192b7d36",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaebb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de9feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(df[\"demand\"], bins=40)\n",
    "plt.title(\"Histogram: demand (kolla outliers)\")\n",
    "plt.xlabel(\"demand\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee04d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(df[\"marketing_spend\"], df[\"demand\"], alpha=0.5)\n",
    "plt.title(\"Scatter: marketing_spend vs demand\")\n",
    "plt.xlabel(\"marketing_spend\")\n",
    "plt.ylabel(\"demand\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b8155",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(numeric_only=True)\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "sns.heatmap(corr, annot=True, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de152f3",
   "metadata": {},
   "source": [
    "## Train / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97324b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"demand\"])\n",
    "y = df[\"demand\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e9483",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68aa870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Egen baseline: gissa alltid train-medelvärdet\n",
    "baseline_value = y_train.mean()\n",
    "y_pred_baseline = np.full(len(y_test), baseline_value)\n",
    "\n",
    "baseline_mae = mean_absolute_error(y_test, y_pred_baseline)\n",
    "baseline_rmse = root_mean_squared_error(y_test, y_pred_baseline)\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(\"Egen baseline (train-mean)\")\n",
    "print(f\"MAE:  {baseline_mae:.2f}\")\n",
    "print(f\"RMSE: {baseline_rmse:.2f}\")\n",
    "print(f\"R²:   {baseline_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3796ab70",
   "metadata": {},
   "source": [
    "## Jämför modeller med CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9282e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge(alpha=1.0)\": Ridge(alpha=1.0, random_state=RANDOM_SEED)\n",
    "}\n",
    "\n",
    "scoring = {\n",
    "    \"mae\": \"neg_mean_absolute_error\",\n",
    "    \"rmse\": \"neg_root_mean_squared_error\",\n",
    "    \"r2\": \"r2\"\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, model in models.items():\n",
    "    pipe = Pipeline(steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "\n",
    "    out = cross_validate(pipe, X_train, y_train, cv=cv, scoring=scoring)\n",
    "    rows.append({\n",
    "        \"model\": name,\n",
    "        \"CV_MAE\": -out[\"test_mae\"].mean(),\n",
    "        \"CV_RMSE\": -out[\"test_rmse\"].mean(),\n",
    "        \"CV_R2\": out[\"test_r2\"].mean()\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c8c76e",
   "metadata": {},
   "source": [
    "## Er Uppgift: välj primär metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90385eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Välj EN primär metric baserat på ert scenario.\n",
    "# Skriv exakt en av: \"mae\"  \"rmse\"  \"r2\"\n",
    "PRIMARY_METRIC = \"mae\"  # <-- ÄNDRA här\n",
    "\n",
    "allowed_metrics = {\"mae\", \"rmse\", \"r2\"}\n",
    "if PRIMARY_METRIC not in allowed_metrics:\n",
    "    raise ValueError(f\"PRIMARY_METRIC måste vara en av {allowed_metrics}. Du skrev: {PRIMARY_METRIC}\")\n",
    "\n",
    "PRIMARY_METRIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e4deb",
   "metadata": {},
   "source": [
    "## GridSearchCV på Ridge alpha\n",
    "om scoring i GridSearchCV (negativa värden)  \n",
    "GridSearchCV vill alltid MAXIMERA ett score.\n",
    "\n",
    "För MAE/RMSE är lägre bättre i verkligheten, därför använder scikit-learn en negativ variant:\n",
    "- neg_mean_absolute_error\n",
    "- neg_root_mean_squared_error\n",
    "\n",
    "Det betyder: **högre (mindre negativt) är bättre**\n",
    "Exempel: **-23 är bättre än -30** (för -23 ligger närmare 0 → mindre fel).  \n",
    "\n",
    "\n",
    "> **Målet här är att optimera modellen så mycket som möjligt:**  \n",
    "> Starta grovt → förfina runt bästa alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_map = {\n",
    "    # scikit-learn använder ofta 'neg_' för loss-mått så att \"större är bättre\" i GridSearch.\n",
    "    # Det betyder: när vi maximerar ett negativt tal så minimerar vi egentligen felet.\n",
    "    \"mae\": \"neg_mean_absolute_error\",\n",
    "    \"rmse\": \"neg_root_mean_squared_error\",\n",
    "    \"r2\": \"r2\",\n",
    "}\n",
    "\n",
    "# Pipeline = en kedja av steg som alltid körs i samma ordning.\n",
    "# 1) imputer: fyller ev. saknade värden (NaN) med medianen (robust mot outliers).\n",
    "# 2) scaler: standardiserar features (viktigt för Ridge/linjära modeller).\n",
    "# 3) model: själva Ridge-regressionen.\n",
    "ridge_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", Ridge(random_state=RANDOM_SEED)),\n",
    "])\n",
    "\n",
    "# =============================\n",
    "# TODO (NI FYLLER I): alpha-grid\n",
    "# =============================\n",
    "# alpha styr hur stark regularisering vi har.\n",
    "# - Liten alpha => mer flexibel modell (kan passa träningsdata mer).\n",
    "# - Stor alpha  => mer \"straff\" => koefficienter pressas mot 0 => enklare modell.\n",
    "#\n",
    "# Tips:\n",
    "# - Testa gärna värden som spänner över flera storleksordningar.\n",
    "# - Ni kan skriva en lista manuellt eller använda t.ex. np.logspace(...)\n",
    "ALPHA_GRID = [\n",
    "    # TODO: Lägg in alpha-värden att testa (flera storleksordningar)\n",
    "    # Exempel på format: 0.001, 0.01, 0.1, 1.0, 10.0\n",
    "]\n",
    "\n",
    "if len(ALPHA_GRID) == 0:\n",
    "    raise ValueError(\"ALPHA_GRID är tom. Fyll i en lista med alpha-värden att testa.\")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__alpha\": ALPHA_GRID\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    ridge_pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=scoring_map[PRIMARY_METRIC],\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best alpha:\", grid.best_params_)\n",
    "print(f\"Best CV score ({PRIMARY_METRIC}):\", grid.best_score_, \"(notera: neg om MAE/RMSE)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a367bb26",
   "metadata": {},
   "source": [
    "## Sluttest på test-setet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72285c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "test_mae = mean_absolute_error(y_test, y_pred)\n",
    "test_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"TEST result (bästa tuned Ridge)\")\n",
    "print(f\"MAE:  {test_mae:.2f}\")\n",
    "print(f\"RMSE: {test_rmse:.2f}\")\n",
    "print(f\"R²:   {test_r2:.3f}\")\n",
    "print(\"Primär metric:\", PRIMARY_METRIC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d7c73",
   "metadata": {},
   "source": [
    "## Förbättring mot baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Förbättring mot baseline (positivt = bättre)\")\n",
    "print(f\"Δ MAE:  {baseline_mae - test_mae:.2f}\")\n",
    "print(f\"Δ RMSE: {baseline_rmse - test_rmse:.2f}\")\n",
    "print(f\"Δ R²:   {test_r2 - baseline_r2:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
